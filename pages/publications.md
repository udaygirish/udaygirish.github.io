---
layout: page
title: Publications
permalink: /publications/
weight: 3
---

# **Publications**

[An Artificial Intelligence Approach for Automated Dynamic Ultrasound Measurement in the Assessment of Patellar Instability" by He, Xingxin; Crasta, Nikitha; Maradana, Uday Girish; Varadarajan, Kartik Mangudi; Tanaka, Miho J.; Liu, Fang]() (In Review)
<br>
<ul>    
This study introduces an AI-based Ultrasound Tracking System (AUTS) for dynamic assessment of patellofemoral joint function. Using SAM for segmentation and PIPs for point tracking, AUTS measures Medial Patellofemoral Distance (MPFD) frame-by-frame from ultrasound videos. Tested on 42 knees, AUTS showed strong agreement with manual measurements and provided additional metrics like MPFD velocity and acceleration, improving diagnostic reliability for patellar instability.
</ul>
<br>


[Uday Girish, M et.al. ”RIGGU: A Semi-humanoid Robot Platform for Speech and Image Recognition” in
Intelligent Systems, Technologies and Applications, 2020 (Springer)](https://link.springer.com/chapter/10.1007%2F978-981-15-3914-5_3)
<br>
<ul>    
RIGGU is a semi-humanoid interactive robot that is developed for different applications such as hospitality, treating autism, and assisting aged people. This paper proposes the integration of object, face, emotion recognition, and navigation of a semi-humanoid robot platform using the Robot Operating System (ROS).   
</ul>
<br>

[Aniket Patil, Mandeep Singh, Uday Girish Maradana, Nitin J.Sanket "MinNav: Minimalist Navigation using Optical flow for Active Tiny Aerial Robots"](https://pear.wpi.edu/research/minnav.html)
<br>
<ul>    
Navigation using a monocular camera is pivotal for autonomous operation on tiny aerial robots due to their perfect balance of versatility, cost and accuracy. In this paper, we introduce MinNav, a navigation stack based on optical flow and its uncertainty to fly through a scene that has static and dynamic obstacles and unknown-shaped gaps without any prior knowledge of the scene components and/or their locations/ordering. We further enhance the success rate by employing the activeness of the robot to move around in an exploratory way to find obstacles and navigate through the scene. We successfully evaluate and demonstrate the proposed approach in many real-world experiments in various environments that contain static and dynamic obstacles and unknown-shaped gaps with an overall success rate of 70\%. To the best of our knowledge, this is the first solution to tackle all the aforementioned navigation cases without prior knowledge using a monocular camera. Our approach is on par in performance with methods that utilize metric depth or relative monocular depth with factors of magnitude less computation required and can readily run onboard tiny aerial robots.

</ul>
<br>